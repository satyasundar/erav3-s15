wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

Model Statistics:
Total Parameters: 688,702,098
Model Size: 2627.19 MB
Device: mps
Batch Size: 4
Accumulation Steps: 8
Sequence Length: 256
Learning Rate: 0.0001
--------------------------------------------------

Epoch 1/5
Step 0, Loss: 46.5964, Scaled Loss: 5.8246, LR: 4.00e-06, Accumulation Step: 1/8
Step 10, Loss: 46.2109, Scaled Loss: 5.7764, LR: 4.00e-06, Accumulation Step: 3/8
Step 20, Loss: 45.8798, Scaled Loss: 5.7350, LR: 4.00e-06, Accumulation Step: 5/8
Step 30, Loss: 45.1243, Scaled Loss: 5.6405, LR: 4.00e-06, Accumulation Step: 7/8
Step 40, Loss: 44.5579, Scaled Loss: 5.5697, LR: 4.00e-06, Accumulation Step: 1/8
Step 50, Loss: 44.0808, Scaled Loss: 5.5101, LR: 4.00e-06, Accumulation Step: 3/8
Step 60, Loss: 43.4014, Scaled Loss: 5.4252, LR: 4.00e-06, Accumulation Step: 5/8
Step 70, Loss: 43.2992, Scaled Loss: 5.4124, LR: 4.00e-06, Accumulation Step: 7/8
Step 80, Loss: 42.5501, Scaled Loss: 5.3188, LR: 4.01e-06, Accumulation Step: 1/8
Step 90, Loss: 41.7548, Scaled Loss: 5.2194, LR: 4.01e-06, Accumulation Step: 3/8
Step 100, Loss: 41.6344, Scaled Loss: 5.2043, LR: 4.01e-06, Accumulation Step: 5/8
Step 110, Loss: 41.3968, Scaled Loss: 5.1746, LR: 4.01e-06, Accumulation Step: 7/8
Step 120, Loss: 40.5086, Scaled Loss: 5.0636, LR: 4.01e-06, Accumulation Step: 1/8
Step 130, Loss: 39.8340, Scaled Loss: 4.9792, LR: 4.02e-06, Accumulation Step: 3/8
Step 140, Loss: 39.8251, Scaled Loss: 4.9781, LR: 4.02e-06, Accumulation Step: 5/8
Step 150, Loss: 38.9670, Scaled Loss: 4.8709, LR: 4.02e-06, Accumulation Step: 7/8
Step 160, Loss: 37.3656, Scaled Loss: 4.6707, LR: 4.02e-06, Accumulation Step: 1/8
Step 170, Loss: 36.7511, Scaled Loss: 4.5939, LR: 4.03e-06, Accumulation Step: 3/8
Step 180, Loss: 37.2103, Scaled Loss: 4.6513, LR: 4.03e-06, Accumulation Step: 5/8
Step 190, Loss: 35.7671, Scaled Loss: 4.4709, LR: 4.03e-06, Accumulation Step: 7/8
Step 200, Loss: 37.5680, Scaled Loss: 4.6960, LR: 4.04e-06, Accumulation Step: 1/8
Step 210, Loss: 34.6407, Scaled Loss: 4.3301, LR: 4.04e-06, Accumulation Step: 3/8
Step 220, Loss: 35.0841, Scaled Loss: 4.3855, LR: 4.04e-06, Accumulation Step: 5/8
Step 230, Loss: 34.0282, Scaled Loss: 4.2535, LR: 4.05e-06, Accumulation Step: 7/8
/opt/anaconda3/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.4
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.

Model Statistics:
Total Parameters: 688,702,098
Model Size: 2627.19 MB
Device: mps
Batch Size: 4
Accumulation Steps: 8
Sequence Length: 256
Learning Rate: 0.0001
--------------------------------------------------

Epoch 1/5
Step 200, Loss: 36.3152, Scaled Loss: 4.5394, LR: 4.04e-06, Accumulation Step: 1/8
'HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/HuggingFaceTB/smollm-corpus/resolve/3ba9d605774198c5868892d7a8deda78031a781f/cosmopedia-v2/train-00000-of-00104.parquet
Retrying in 1s [Retry 1/5].
'(ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)"), '(Request ID: 9ba332f0-f751-423d-8b18-064ec9da309f)')' thrown while requesting GET https://huggingface.co/datasets/HuggingFaceTB/smollm-corpus/resolve/3ba9d605774198c5868892d7a8deda78031a781f/cosmopedia-v2/train-00000-of-00104.parquet
Retrying in 2s [Retry 2/5].
Step 210, Loss: 35.7971, Scaled Loss: 4.4746, LR: 4.04e-06, Accumulation Step: 3/8
